{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I think its time to go back to creating the final Airtable tool.\n",
    "# In hindsight, and given that ToolNode can execute tools in parallel, I've given up the idea of using the batch_upsert method.\n",
    "# This will be better for simplicity and modularity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First: the read tool\n",
    "\n",
    "from typing import List\n",
    "from langchain_core.tools import tool\n",
    "from langchain.pydantic_v1 import Field, BaseModel\n",
    "from pyairtable import Api\n",
    "import os\n",
    "\n",
    "@tool # Should be as simple as this\n",
    "def read_tool(\n",
    "    only_active: bool = Field(default=False, description=\"Whether to only return active tasks or all tasks.\")\n",
    ") -> List[dict]:\n",
    "    \"\"\"\n",
    "    Gets all tasks currently attributed to the user.\n",
    "    By default, it returns all tasks.\n",
    "    Setting only_active to True will return only pending tasks.\n",
    "    Should be used to save prompt space in specific cases.\n",
    "    \"\"\"\n",
    "    api = Api(os.environ['AIRTABLE_ACCESS_TOKEN'])\n",
    "    table = api.table(os.environ['AIRTABLE_BASE_ID'], 'Tasks')\n",
    "    if only_active:\n",
    "        return table.all(view='Pending')\n",
    "    return table.all()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's test it\n",
    "read_tool.invoke(dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second: the create tool\n",
    "\n",
    "# Now we start needing a pydantic model for the input\n",
    "from enum import Enum\n",
    "from typing import Optional\n",
    "\n",
    "class StatusEnum(str, Enum):\n",
    "    A_INICIAR = 'A iniciar'\n",
    "    EM_ANDAMENTO = 'Em andamento'\n",
    "    CONCLUIDA = 'Concluída'\n",
    "    CANCELADA = 'Cancelada'\n",
    "    MESCLADA = 'Mesclada'\n",
    "\n",
    "class CreateTaskFields(BaseModel):\n",
    "    Task: str = Field(description=\"A short description of the task.\", min_length=1)\n",
    "    Description: Optional[str] = Field(description=\"A more detailed description of the task.\")\n",
    "    Status: StatusEnum = Field(description=\"The status of the task. 'Mesclada' means the task was merged with another one.\")\n",
    "\n",
    "@tool\n",
    "def create_tool(records: List[CreateTaskFields]) -> List[dict]:\n",
    "    \"\"\"\n",
    "    Should always be preceded by a read_tool call, so one can know the current state of the tasks.\n",
    "    Should only be used if there are no tasks about the same subject, that can be updated instead.\n",
    "    Creates one or more tasks in the user's task list.\n",
    "    Tasks should only contain necessary information, and only information given by the user.\n",
    "    \"\"\"\n",
    "    api = Api(os.environ['AIRTABLE_ACCESS_TOKEN'])\n",
    "    table = api.table(os.environ['AIRTABLE_BASE_ID'], 'Tasks')\n",
    "\n",
    "    # We need to convert the records to a format that Airtable can understand\n",
    "    records = [record.dict() for record in records]\n",
    "    return table.batch_create(records=records)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starting to need a graph here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated # This is what will allow us to pass the reductor function to our State class\n",
    "\n",
    "from typing_extensions import TypedDict # So we can better 'lock' the datatypes for our state attributes\n",
    "\n",
    "from langgraph.graph import StateGraph # The main structure of our graph\n",
    "from langgraph.graph.message import add_messages # This is a prebuilt function that does the reductor job. Could be manually implemented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    \"\"\"\n",
    "    The State class is a TypedDict that will hold the attributes of our state.\n",
    "    The add_messages reductor function will guarantee that when a node simply returns the new message, it is appended instead of replacing the previous ones.\n",
    "    \"\"\"\n",
    "    messages: Annotated[list, add_messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_builder = StateGraph(State)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The model...\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model='gpt-4o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binding\n",
    "\n",
    "llm_with_tools = llm.bind_tools([read_tool, create_tool])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The LLM node itself\n",
    "def chatbot(state: State):\n",
    "    return {\"messages\":[llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "graph_builder.add_node('chatbot', chatbot)\n",
    "\n",
    "graph_builder.set_entry_point('chatbot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The tool node now\n",
    "\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "tool_node = ToolNode(tools=[read_tool, create_tool])\n",
    "\n",
    "graph_builder.add_node('tool_node', tool_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "\n",
    "def route_tools(state: State,) -> Literal[\"tools\",\"__end__\"]:\n",
    "    \"\"\"\n",
    "    Use in the conditional_edge to route to the ToolNode if the last message\n",
    "    has tool calls. Otherwise, route to the end.\n",
    "    The values returned here are arbitrary, but it makes sense to name them after the node in the graph they should route to.\n",
    "    \"\"\"\n",
    "\n",
    "    # First we must get the last message from the state.\n",
    "    # We are looking necessarily for an AIMessage, since those are the ones that call tools.\n",
    "    # The introduction notebook adds a few validation if-elses, some of which are unnecessary.\n",
    "\n",
    "    # A try-except solves my current needs\n",
    "    try:\n",
    "        last_message = state[\"messages\"][-1]\n",
    "    except: \n",
    "        raise ValueError(f\"No messages found in input state to tool_edge: {state}\")\n",
    "    \n",
    "    # Now we check if the last message has tool calls.\n",
    "    if hasattr(last_message, \"tool_calls\") and len(last_message.tool_calls) > 0:\n",
    "        return \"tools\" # Logic being: 'Look, there's a tool call. So we should route to the 'tools' node.\n",
    "    return \"__end__\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_builder.add_conditional_edges('chatbot', route_tools, {'tools':'tool_node', '__end__':'__end__'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_builder.add_edge('tool_node', 'chatbot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Once again visualizing the graph\n",
    "\n",
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, BaseMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing no tool usage.\n",
    "user_input = HumanMessage(\"Eu preciso estudar pra prova de matemática.\")\n",
    "\n",
    "for event in graph.stream({\"messages\": user_input}, stream_mode='values'):\n",
    "    event['messages'][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Third: the update tool\n",
    "\n",
    "\n",
    "class UpdateTaskFields(TypedDict):\n",
    "    Description: Optional[str] = Field(description=\"An updated description of the task, if needed.\")\n",
    "    Status: StatusEnum = Field(description=\"The status of the task. 'Mesclada' means the task was merged with another one.\")\n",
    "\n",
    "class UpdateTaskRecord(UpdateTaskFields):\n",
    "    id: str = Field(description=\"The unique id for the record that'll be updated. Must be preexisting.\", pattern='rec[A-Za-z0-9]{14}')\n",
    "    fields: UpdateTaskFields = Field(description=\"The fields to be updated with their new values.\")\n",
    "    \n",
    "\n",
    "@tool\n",
    "def update_tool(records: List[UpdateTaskRecord]) -> List[dict]:\n",
    "    \"\"\"\n",
    "    Should always be preceded by a read_tool call, so one can know the current state of the tasks.\n",
    "    Alters one or more existing tasks in the user's task list.\n",
    "    Tasks should only contain necessary information, and only information given by the user.\n",
    "    \"\"\"\n",
    "    api = Api(os.environ['AIRTABLE_ACCESS_TOKEN'])\n",
    "    table = api.table(os.environ['AIRTABLE_BASE_ID'], 'Tasks')\n",
    "\n",
    "    # We need to convert the records to a format that Airtable can understand\n",
    "    #records = [record.dict() for record in records]\n",
    "    return table.batch_update(records=records)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recreating the graph\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "llm = ChatOpenAI(model='gpt-4o').bind_tools([read_tool, create_tool, update_tool])\n",
    "\n",
    "def chatbot(state: State):\n",
    "    return {\"messages\":[llm.invoke(state[\"messages\"])]}\n",
    "\n",
    "graph_builder.add_node('chatbot', chatbot)\n",
    "\n",
    "graph_builder.set_entry_point('chatbot')\n",
    "\n",
    "tool_node = ToolNode(tools=[read_tool, create_tool, update_tool])\n",
    "\n",
    "graph_builder.add_node('tool_node', tool_node)\n",
    "\n",
    "graph_builder.add_conditional_edges('chatbot', route_tools, {'tools':'tool_node', '__end__':'__end__'})\n",
    "\n",
    "graph_builder.add_edge('tool_node', 'chatbot')\n",
    "\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see\n",
    "\n",
    "user_input = HumanMessage(\"Remove as duplicatas das minhas tarefas por favor?\")\n",
    "\n",
    "for event in graph.stream({\"messages\": user_input}, stream_mode='values'):\n",
    "    event['messages'][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
